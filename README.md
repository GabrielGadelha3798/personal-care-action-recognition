# personal-care-action-recognition

Reconhecimento de aÃ§Ãµes relacionadas a cuidados pessoais a partir de vÃ­deos.  
Este projeto utiliza deep learning para classificar aÃ§Ãµes em vÃ­deos, focando na identificaÃ§Ã£o de atividades de autocuidado, como escovar os dentes, aplicar maquiagem, cortar o cabelo, entre outros.

---

## ğŸ“¦ Estrutura do Projeto

A seguir, uma visÃ£o geral da estrutura do projeto e da funÃ§Ã£o de cada componente:

```
personal-care-action-recognition/
â”‚
â”œâ”€â”€ checkpoints/                        # Pesos dos modelos salvos durante o treinamento
â”‚
â”œâ”€â”€ data/                               # Dados utilizados no projeto
â”‚   â”œâ”€â”€ Raw/                            # Dataset puro, nÃ£o processado
â”‚   â”œâ”€â”€ Split/                          # VersÃ£o processada do dataset
|       â”œâ”€â”€ split_info/                 # Arquivos de anotaÃ§Ã£o para treino e teste
|       â”œâ”€â”€ split_info-filtered/        # VersÃ£o filtrada dos splits (apenas classes de interesse)
|       â”œâ”€â”€ UCF101/                     # Dataset original UCF101 organizado por classes
|                  
â”‚
â”œâ”€â”€ docs/                               # DocumentaÃ§Ã£o de planejamento do projeto
â”‚   â”œâ”€â”€ planejamento.md             
â”‚   â””â”€â”€ planejamento.pdf            
â”‚
â”œâ”€â”€ notebooks/                          # Notebooks de desenvolvimento e anÃ¡lise
â”‚   â”œâ”€â”€ environment_validation.ipynb    # Teste de validaÃ§Ã£o do ambiente e dependÃªncias
â”‚   â”œâ”€â”€ EDA.ipynb                       # AnÃ¡lise exploratÃ³ria dos dados
â”‚   â”œâ”€â”€ r3d_18_training.ipynb           # Treinamento do modelo R3D_18
â”‚   â””â”€â”€ video_classification.ipynb      # Testes e geraÃ§Ã£o dos vÃ­deos finais + JSON
â”‚
â”œâ”€â”€ outputs/                        # VÃ­deos processados e arquivos JSON gerados
â”‚
â”œâ”€â”€ src/                            # Arquivos de cÃ³digo principais do projeto
â”‚   â”œâ”€â”€ data/                       # FunÃ§Ãµes de preparaÃ§Ã£o dos dados
â”‚   â”‚   â”œâ”€â”€ data_preparation.py
â”‚   â”‚   â””â”€â”€ ucf101_dataset.py
â”‚   â”œâ”€â”€ train/                      # FunÃ§Ãµes de treinamento do modelo
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â”œâ”€â”€ utils/                      # UtilitÃ¡rios e funÃ§Ãµes de apoio
â”‚   |      â””â”€â”€ utils.py
â”‚   |
|   â””â”€â”€ video/                          # Processamento de vÃ­deos
â”‚       â””â”€â”€ video_process.py
â”‚
â”œâ”€â”€ inference.py                    # Script para realizar inferÃªncia em novos vÃ­deos
â”‚
â”œâ”€â”€ requirements.txt                # DependÃªncias do projeto
â””â”€â”€ README.md                       # Este arquivo
```

---

## ğŸš€ Como rodar o projeto

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/GabrielGadelha3798/personal-care-action-recognition
cd personal-care-action-recognition
```

### 2. Crie o ambiente virtual e ative

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Valide o ambiente (opcional)

Abra e execute o notebook:

```
notebooks/environment_validation.ipynb
```

---

## ğŸ§© Funcionalidades principais

- **AnÃ¡lise de dados**: Notebook `notebooks/EDA.ipynb` para anÃ¡lise exploratÃ³ria da base de dados.
- **Treinamento**: Utilize o notebook `notebooks/r3d_18_training.ipynb` para treinar o modelo utilizando a arquitetura R3D_18 prÃ©-treinada no dataset Kinetics-400.
- **InferÃªncia**: Execute o script `inference.py` para realizar a inferÃªncia sobre um vÃ­deo de entrada, gerando o vÃ­deo com as prediÃ§Ãµes e os JSONs correspondentes.
- **GeraÃ§Ã£o de vÃ­deos finais**: Notebook `notebooks/video_classification.ipynb` para testes e criaÃ§Ã£o dos vÃ­deos finais processados.

---

## ğŸ“„ Planejamento

Todo o planejamento e roadmap do projeto estÃ£o documentados no arquivo:

```
docs/planejamento.pdf
```

Nele estÃ£o descritos:
- Etapas do desenvolvimento
- PrÃ³ximos passos
- DecisÃµes de arquitetura e modelo
- Desafios encontrados e soluÃ§Ãµes aplicadas

---

## ğŸ—‚ï¸ Dados

- A pasta `data/Raw` contÃ©m o dataset original bruto.
- A pasta `data/Split` possui o dataset organizado e separado para treino e teste, de acordo com os arquivos de anotaÃ§Ã£o disponÃ­veis em `split_info/`.
- Cada classe Ã© representada por uma pasta contendo vÃ­deos das aÃ§Ãµes correspondentes.

---

## ğŸ’¡ ObservaÃ§Ãµes finais

- O projeto foi desenvolvido em Python com PyTorch e foco na manipulaÃ§Ã£o de vÃ­deos.
- Os resultados gerados sÃ£o salvos na pasta `outputs/`, incluindo vÃ­deos com as prediÃ§Ãµes visuais e arquivos JSON detalhando as classes e pontuaÃ§Ãµes.